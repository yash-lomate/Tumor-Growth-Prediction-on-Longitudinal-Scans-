{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumor Growth Prediction - Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the tumor growth prediction framework for training and inference on longitudinal medical imaging data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from src.models import Conv3DLSTM, Recurrent3DCNN, Baseline3DCNN\n",
    "from src.data import TumorGrowthDataset, LongitudinalDataLoader\n",
    "from src.training import Trainer, CombinedLoss, compute_metrics\n",
    "from src.utils import Config, visualize_prediction\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from file\n",
    "config = Config.from_file('configs/default_config.yaml')\n",
    "\n",
    "# Or create configuration programmatically\n",
    "# config = Config()\n",
    "\n",
    "# Print configuration\n",
    "print(\"Model Configuration:\")\n",
    "for key, value in config.to_dict().items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data\n",
    "\n",
    "Create data loaders for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader = LongitudinalDataLoader.create_dataloaders(\n",
    "    data_dir=config.data_dir,\n",
    "    batch_size=config.batch_size,\n",
    "    num_time_steps=config.num_time_steps,\n",
    "    train_split=config.train_split,\n",
    "    val_split=config.val_split,\n",
    "    num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample batch\n",
    "inputs, targets = next(iter(train_loader))\n",
    "\n",
    "print(f\"Input shape: {inputs.shape}\")  # (batch, time_steps, channels, D, H, W)\n",
    "print(f\"Target shape: {targets.shape}\")  # (batch, channels, D, H, W)\n",
    "\n",
    "# Visualize first sample\n",
    "sample_input = inputs[0]  # (time_steps, channels, D, H, W)\n",
    "sample_target = targets[0]  # (channels, D, H, W)\n",
    "\n",
    "# Plot middle slices of each time step\n",
    "fig, axes = plt.subplots(2, config.num_time_steps, figsize=(16, 8))\n",
    "slice_idx = sample_input.shape[2] // 2\n",
    "\n",
    "for t in range(config.num_time_steps):\n",
    "    # Axial view\n",
    "    axes[0, t].imshow(sample_input[t, 0, slice_idx, :, :], cmap='gray')\n",
    "    axes[0, t].set_title(f'Time {t} - Axial')\n",
    "    axes[0, t].axis('off')\n",
    "    \n",
    "    # Coronal view\n",
    "    axes[1, t].imshow(sample_input[t, 0, :, slice_idx, :], cmap='gray')\n",
    "    axes[1, t].set_title(f'Time {t} - Coronal')\n",
    "    axes[1, t].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model\n",
    "\n",
    "Choose and instantiate a model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Conv3D-LSTM model\n",
    "model = Conv3DLSTM(\n",
    "    in_channels=config.in_channels,\n",
    "    base_features=config.base_features,\n",
    "    hidden_size=config.hidden_size,\n",
    "    num_lstm_layers=config.num_lstm_layers,\n",
    "    num_time_steps=config.num_time_steps,\n",
    "    output_channels=config.output_channels\n",
    ")\n",
    "\n",
    "# Or create Recurrent 3D CNN\n",
    "# model = Recurrent3DCNN(\n",
    "#     in_channels=config.in_channels,\n",
    "#     hidden_channels=[32, 64, 128],\n",
    "#     num_layers=3,\n",
    "#     output_channels=config.output_channels\n",
    "# )\n",
    "\n",
    "# Print model info\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model: {model.__class__.__name__}\")\n",
    "print(f\"Total parameters: {num_params:,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass with sample data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_batch = inputs[:2]  # Take 2 samples\n",
    "    output = model(sample_batch)\n",
    "\n",
    "print(f\"Input shape: {sample_batch.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setup Training\n",
    "\n",
    "Configure loss function, optimizer, and trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create loss function\n",
    "criterion = CombinedLoss(\n",
    "    mse_weight=config.mse_weight,\n",
    "    dice_weight=config.dice_weight,\n",
    "    smooth_weight=config.smooth_weight\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    learning_rate=config.learning_rate,\n",
    "    num_epochs=config.num_epochs,\n",
    "    checkpoint_dir=config.checkpoint_dir,\n",
    "    log_dir=config.log_dir\n",
    ")\n",
    "\n",
    "print(\"Trainer configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Model\n",
    "\n",
    "Start training (note: this may take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Note: For demonstration, you might want to reduce num_epochs\n",
    "# trainer.num_epochs = 5  # Quick demo\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(f\"\\nBest validation loss: {trainer.best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_checkpoint = torch.load('checkpoints/best_model.pth')\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "all_metrics = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute metrics for each sample in batch\n",
    "        for i in range(outputs.shape[0]):\n",
    "            metrics = compute_metrics(outputs[i:i+1], targets[i:i+1])\n",
    "            all_metrics.append(metrics)\n",
    "\n",
    "# Print average metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for key in all_metrics[0].keys():\n",
    "    values = [m[key] for m in all_metrics if m[key] != float('inf')]\n",
    "    if values:\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        print(f\"{key}: {mean_val:.4f} Â± {std_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a test sample\n",
    "test_inputs, test_targets = next(iter(test_loader))\n",
    "test_inputs = test_inputs.to(device)\n",
    "test_targets = test_targets.to(device)\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_inputs)\n",
    "\n",
    "# Visualize first sample\n",
    "visualize_prediction(\n",
    "    test_inputs[0],\n",
    "    predictions[0],\n",
    "    test_targets[0],\n",
    "    save_path='outputs/sample_prediction.png'\n",
    ")\n",
    "\n",
    "print(\"Visualization saved to outputs/sample_prediction.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Future Predictions\n",
    "\n",
    "Generate predictions for multiple future time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Conv3DLSTM, use predict_sequence\n",
    "if hasattr(model, 'predict_sequence'):\n",
    "    with torch.no_grad():\n",
    "        future_predictions = model.predict_sequence(test_inputs[:1])\n",
    "    \n",
    "    print(f\"Future predictions shape: {future_predictions.shape}\")\n",
    "    \n",
    "    # Visualize predictions at different future time steps\n",
    "    fig, axes = plt.subplots(1, future_predictions.shape[1], figsize=(20, 4))\n",
    "    slice_idx = future_predictions.shape[3] // 2\n",
    "    \n",
    "    for t in range(future_predictions.shape[1]):\n",
    "        axes[t].imshow(future_predictions[0, t, 0, slice_idx, :, :].cpu(), cmap='hot')\n",
    "        axes[t].set_title(f'Future T+{t+1}')\n",
    "        axes[t].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# For Recurrent3DCNN, use predict_future\n",
    "elif hasattr(model, 'predict_future'):\n",
    "    with torch.no_grad():\n",
    "        future_predictions = model.predict_future(test_inputs[:1], num_future_steps=3)\n",
    "    \n",
    "    print(f\"Future predictions shape: {future_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading and preparing longitudinal medical imaging data\n",
    "2. Creating and configuring deep learning models for tumor growth prediction\n",
    "3. Training models with appropriate loss functions\n",
    "4. Evaluating model performance with multiple metrics\n",
    "5. Visualizing predictions and future forecasts\n",
    "\n",
    "For more information, see the [README](../README.md) file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
